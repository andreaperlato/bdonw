<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on Andrea Perlato</title>
    <link>/</link>
    <description>Recent content in Homepage on Andrea Perlato</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 May 2016 21:48:51 -0700</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Continuous Probability</title>
      <link>/theorypost/continuous-probability/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/theorypost/continuous-probability/</guid>
      <description>body {text-align: justify}When summarizing a list of numeric values such as heights, it’s not useful to construct a distribution that assigns a proportion to each possible outcome. It is much more practical to define a function that operates on intervals rather than single values. The standard way of doing this is using the cumulative distribution function (CDF). As an example, we define the empirical cumulative distribution function (eCDF) for heights for male adult students.</description>
    </item>
    
    <item>
      <title>How many Monte Carlo are enough?</title>
      <link>/theorypost/how-many-monte-carlo-are-enough/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/theorypost/how-many-monte-carlo-are-enough/</guid>
      <description>body {text-align: justify}Here an example of the The birthday problem solution via Monte Carlo. Suppose you’re in a classroom with 22 people. If we assume this is a randomly selected group, what is the chance that at least two people have the same birthday? 
This is a problem of discrete probability. 
All right, first, note that birthdays can be represented as numbers between 1 and 365.</description>
    </item>
    
    <item>
      <title>The Monty Hall Problem</title>
      <link>/theorypost/the-monty-hall-problem/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/theorypost/the-monty-hall-problem/</guid>
      <description>body {text-align: justify}In the 1970s, there was a game show called Let’s Make a Deal. Monty Hall was the hos, this is where the name of the problem comes from. At some point in the game, contestants were asked to pick one of three doors. Behind one door, there was a prize. The other two had a goat behind them. And this basically meant that you lost.</description>
    </item>
    
    <item>
      <title>Automotive Multivariate Visualization</title>
      <link>/graphpost/automotive-multivariate-visualization/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/graphpost/automotive-multivariate-visualization/</guid>
      <description>body {text-align: justify}This is a session dedicated to multivariate data visualization using some tipical feature of automobile. Here below we can see the matrix of correlation between features and a graphical representation.
 mpg cyl disp hp drat wt qsec vs am gear carbmpg 1.00 -0.85 -0.85 -0.78 0.68 -0.87 0.42 0.66 0.60 0.48 -0.55cyl -0.85 1.00 0.90 0.83 -0.70 0.78 -0.59 -0.81 -0.</description>
    </item>
    
    <item>
      <title>How Neural Network learn? An example of risk of churn.</title>
      <link>/aipost/how-neural-network-learn/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/how-neural-network-learn/</guid>
      <description>body {text-align: justify}Having a one layer neural network (single layer feedforeward) with the output value to be compare to the actual value. Baed on the activation function we have our output. In order to be able to lear, we have to compare the output value with the actual value via the cost funtion which is the half of the squred difference output and actual value.</description>
    </item>
    
    <item>
      <title>Customer segmentation via K-Means &amp; Hierarchical clustering</title>
      <link>/mlpost/customer-segmentation/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/customer-segmentation/</guid>
      <description>body {text-align: justify}Consider to have a big mall in a specific city that contains information of its clients that subcribed to a membership card. The last feature is Spending Score that is a score that the mall computed for each of their clients based on several criteria including for example their income and the number of times per week they show up in the mall and of course, the amount of dollars they spent in a year.</description>
    </item>
    
    <item>
      <title>Assessing the sucess of a new product via multiple classifiers</title>
      <link>/mlpost/estimate-the-sucess-of-a-new-product-with-logistic-regression/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/estimate-the-sucess-of-a-new-product-with-logistic-regression/</guid>
      <description>body {text-align: justify}These are a series of analysis to illustate the main classification algorithms and their advantages. The table shows the business clients of a company that has just launched a new product online. Some of the clients responded positively to the ads by buying the product and other responded negatively by not buying the product. The last column of the table tells for each user if the user bought the product or not.</description>
    </item>
    
    <item>
      <title>Andrea Perlato</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>body { text-align: justify}  I started my caree as a Data Scientist more than 10 years ago in the field of Neuroscience at the University of Verona - School of Medicine, Italy. As point person in data analysis, I studied the single and multi-unit recordings from behaving non human primates. Moreover, I have been conducting psychophysic experiments on human subjects to investigate the brain plasticity in drug addicts.  Find out more.</description>
    </item>
    
  </channel>
</rss>