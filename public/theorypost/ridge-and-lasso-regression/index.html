<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.53" />


<title>Ridge and Lasso Regression - Andrea Perlato</title>
<meta property="og:title" content="Ridge and Lasso Regression - Andrea Perlato">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/graphpost/">Graph</a></li>
    
    <li><a href="/mlpost/">Machine Learning</a></li>
    
    <li><a href="/aipost/">Artificial Intelligence</a></li>
    
    <li><a href="/tspost/">Time Series</a></li>
    
    <li><a href="/theorypost/">Theory</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Ridge and Lasso Regression</h1>

    

    <div class="article-content">
      


<style>
body {
text-align: justify}
</style>
<p><strong>Overfitting</strong> </br> In statistics, overfitting is the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably. An overfitted model is a statistical model that contains more parameters than can be justified by the data. </br> Overfitting is the use of models or procedures that violate <a href="https://en.wikipedia.org/wiki/Occam%27s_razor"><strong>Occam’s razor</strong></a>, for example by including more adjustable parameters than are ultimately optimal, or by using a more complicated approach than is ultimately optimal. </br> The most obvious consequence of overfitting is poor performance on the validation dataset.</p>
<p><strong>Bias-Variance Tradeoff</strong> </br> In statistics and machine learning, the <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"><strong>bias–variance tradeoff</strong></a> is the property of a set of predictive models whereby models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa. </br> Ideally, we would know the exact mathematical formula that describes the relationship between two variables (e.g. height and weight of the mice). </br></p>
<center>
<img src="/img/biasvariancetradeoff.png" style="width:40.0%" />
</center>
<p>To do that, we use the machine learning to approximate the formula. Then, we split the data in train and test. </br> Image now the first machine learning model is a <strong>Linear Regression</strong>, but is not accurate to replicate the curve of the true relationship between height and weight. The inability for a machine learning to capture the true relationship is called <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator"><strong>Bias</strong></a>. Another machine learning model might fit a <strong>Squiggly Line</strong> to the training set, which is super-flexible to fit the training-set. </br> But, when we calculate the Sum of the Squared Error in the Test-set, we probably find that the Linear Line is better than the Squiggly Line, and we call this <strong>Overfitting</strong>. In Machine Learning Lingo, the difference in fitting between Training and Testing is called <a href="https://en.wikipedia.org/wiki/Variance"><strong>Variance</strong></a>. In Machine Learning the <strong>ideal algorithm</strong> need to have <strong>Low Bias</strong> and has to be able to accurately approximate the true relationship. Two commonly used methods to find the best between Simple and Complicated are: <strong>Regularization L1 and L2</strong> </br></p>
<p><strong>L2 Ridge Regression</strong> </br> It is a <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)"><strong>Regularization Method</strong></a> to reduce <a href="https://en.wikipedia.org/wiki/Overfitting"><strong>Overfitting</strong></a>.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://www.rstudio.com/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
  </body>
</html>

