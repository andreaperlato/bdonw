<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Backpropagation on Andrea Perlato</title>
    <link>/tags/backpropagation/</link>
    <description>Recent content in Backpropagation on Andrea Perlato</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/backpropagation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Backpropagation Intuition</title>
      <link>/aipost/backpropagation/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/backpropagation/</guid>
      <description>body {text-align: justify}Introduction  We already know that there is in ANN a Forwward Propagation where the information is entered into the input layer, and then it is propagated forward to get our output values to compare with the actual values that we have in our training set, and then we calculate the errors. Then the errors are back propagated through the network in the opposite direction in order to adjust the weights.</description>
    </item>
    
  </channel>
</rss>