<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Andrea Perlato</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Andrea Perlato</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Quantile Regression in Medical Expenditures</title>
      <link>/mlpost/quantile-regression-in-medical-expenditures/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/quantile-regression-in-medical-expenditures/</guid>
      <description>body {text-align: justify}The Quantile regression gives a more comprehensive picture of the effect of the independent variables on the dependent variable. Instead of estimating the model with average effects using the OLS linear model, the quantile regression produces different effects along the distribution (quantiles) of the dependent variable. The dependent variable is continuous with no zeros or too many repeated values.  Examples include estimating the effects of household income on food expenditures for low- and high-expenditure households, what are the factors influencing total medical expenditures for people with low, medium and high expenditures.</description>
    </item>
    
    <item>
      <title>Naive Bayes Classification</title>
      <link>/mlpost/naive-bayes-classification/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/naive-bayes-classification/</guid>
      <description>body {text-align: justify}Naive Bayes is an effective and commonly-used, machine learning classifier. It is a probabilistic classifier that makes classifications using the Maximum A Posteriori decision rule in a Bayesian setting. It can also be represented using a very simple Bayesian network. Naive Bayes classifiers have been especially popular for text classification, and are a traditional solution for problems such as spam detection.
An intuitive explanation for the Maximum A Posteriori Probability MAP is to think probabilities as degrees of belief.</description>
    </item>
    
    <item>
      <title>Extreme Gradient Boosting Algorithm</title>
      <link>/mlpost/extreme-gradient-boosting-algorithm/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/extreme-gradient-boosting-algorithm/</guid>
      <description>body {text-align: justify}Extreme Gradient Boosting is extensively used because is fast and accurate, and can handle missing values.  Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.</description>
    </item>
    
    <item>
      <title>Customer segmentation via K-Means &amp; Hierarchical clustering</title>
      <link>/mlpost/customer-segmentation/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/customer-segmentation/</guid>
      <description>body {text-align: justify}Consider to have a big mall in a specific city that contains information of its clients that subcribed to a membership card. The last feature is Spending Score that is a score that the mall computed for each of their clients based on several criteria including for example their income and the number of times per week they show up in the mall and of course, the amount of dollars they spent in a year.</description>
    </item>
    
    <item>
      <title>Assessing the sucess of a new product via multiple classifiers</title>
      <link>/mlpost/estimate-the-sucess-of-a-new-product-with-logistic-regression/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/mlpost/estimate-the-sucess-of-a-new-product-with-logistic-regression/</guid>
      <description>body {text-align: justify}These are a series of analysis to illustate the main classification algorithms and their advantages. The table shows the business clients of a company that has just launched a new product online. Some of the clients responded positively to the ads by buying the product and other responded negatively by not buying the product. The last column of the table tells for each user if the user bought the product or not.</description>
    </item>
    
  </channel>
</rss>