---
title: How Neural Network learn?
author: andrea perlato
date: '2019-01-14'
slug: how-neural-network-learn
categories:
  - artificial intelligence
tags:
  - gradient descent
  - ANN
---



<style>
body {
text-align: justify}
</style>
<p>Having a one layer neural network (single layer feedforeward) with the output value to be compare to the actual value. Baed on the activation function we have our output. In order to be able to lear, we have to compare the output value with the actual value via the cost funtion which is the half of the squred difference output and actual value. Cost function says that is the error in our prediction: the lower the cost function the closer the output value to output value. So, the information is going back and our weights have been updated till we minimize the cost function. This process is called <a href="https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications"><strong>back propagation</strong></a>.</p>
<p><strong>Gradien Descent</strong> </br> How can we minimize the cost function? </br> The figure represent our cost function and represent the best way to find the best soution for our weights. We continue to calcuate the slope in the points represented by the red dot till we find the best weights, the best situation that inimize the cost function.</p>
<div class="figure">
<img src="/AIPost/2019-01-14-how-neural-network-learn_files/costfunction.PNG" alt="cost function" />
<p class="caption">cost function</p>
</div>
