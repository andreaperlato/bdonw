---
title: Gradient Descent Step by Step
author: andrea perlato
date: '2019-02-13'
slug: gradient-descent-step-by-step
categories:
  - theory
tags:
  - gradient descent
---



<style>
body {
text-align: justify}
</style>
<p><strong>INTRODUCTION</strong> </br> In statistics, Machine Learning and other Data Science fields, we optimize a lot of stuff. For example in linear regresion, we optimize the Intercept and Slope, or when we use Logistic Regression we optimize the squiggle. Moreover, in t-SNE we optimize clusters. The interesting thing is that gradient descent can optimize all these things and much more. A good example is the <strong>Sum of the Squared Residuals</strong> in Regression: in Machine Learning lingo this is a type of <strong>Loss Function</strong>. The <strong>Residual</strong> is the difference between the Observed Value and the Predicted Value.</p>
<center>
<img src="/img/gradientdescentregression.png" style="width:80.0%" />
</center>
